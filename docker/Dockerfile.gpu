FROM pytorch/pytorch:2.2.0-cuda12.1-cudnn8-devel

ARG DEBIAN_FRONTEND=noninteractive

# Install necessary system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    curl \
    wget \
    lsof && \
    rm -rf /var/lib/apt/lists/*

# update pip to support for whl.metadata -> less downloading
RUN pip install --no-cache-dir -U "pip>=24"

# create a working directory
RUN mkdir /app
WORKDIR /app

# install the requirements for running the whisper-live server
COPY requirements /app/requirements
COPY translation_tools /app/translation_tools
COPY certificates /app/certificates
COPY madlad400-3b /app/madlad400-3b
COPY *.sh /app/
RUN chmod +x /app/*.sh

# make the paths of the nvidia libs installed as wheels visible. equivalent to:
# export LD_LIBRARY_PATH=`python3 -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + ":" + os.path.dirname(nvidia.cudnn.lib.__file__))'`
ENV LD_LIBRARY_PATH="/usr/local/lib/python3.10/site-packages/nvidia/cublas/lib:/usr/local/lib/python3.10/site-packages/nvidia/cudnn/lib"

COPY whisper_live /app/whisper_live
COPY run_server.py /app

CMD ["bash", "run.sh"]
